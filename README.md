## 目的
本研究計算資訊檢索中給定用戶查詢的每個文件的相關性分數。

## 方法
1.語料庫：本研究使用的語料庫為WT2g數據集，包含2GB的網頁文件。該集合由40個TREC查詢組成，格式符合標準TREC格式，包括主題標題、描述和敘述。

2.Pyserini：為了支持索引、搜索、評分和評估功能，利用了Pyserini的工具包，該工具包利用Anserini/Lucene JAVA Class。Anserini是一個橋接器，調用Apache Lucene，一個高效且功能豐富的全文搜索引擎庫。

3.索引：對於WT2g語料庫，我們構建了兩個索引：一個使用Porter詞幹處理，另一個不使用。應用Porter詞幹處理旨在通過將詞匯還原為其根形式來提高檢索準確性。這些索引促進了高效的檢索操作。

4.搜索：隨後我們對WT2g語料庫執行了40個TREC查詢，為每個查詢返回一個排名的相關文件列表（前1000個）。我們使用了多種語言模型，包括OKAPI BM25模型和兩種不同平滑技術的語言模型：Maximum Likelihood Estimates with Laplace smoothing 和 Jelinek-Mercer smoothing。

5.排名和語言模型的性能評估：檢索到的文件的評分涉及應用三種加一種不同的語言模型，並通過treceval.pl評估每個模型的性能。

## 結論
詞幹處理顯著增強了語言模型的有效性。通過比較不同的平滑技術和引入機器學習方法，凸顯了性能指標之間細微的權衡。傳統語言模型如Jelinek-Mercer和MLE在與精度相關的指標上表現優越，而機器學習方法XGBoost儘管在MAP和前10個精度上表現較低，卻在檢索更高量的相關文件方面展現了獨特的優勢。最終，方法論的選擇取決於資訊檢索場景中的具體優先順序和偏好。
